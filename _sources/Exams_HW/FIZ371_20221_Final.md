---
jupyter:
  jupytext:
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.11.5
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# Final Exam
**FIZ371 - Scientific & Technical Calculations | 20/01/2023**

Emre S. Tasci <emre.tasci@hacettepe.edu.tr>
Eng. Physics Dept.  
Hacettepe University  
Ankara, Turkey

You can solve the problems analytically or stochastically, it's up to you. You can present your solution having been calculated on a paper, or as a jupyter notebook, or as a mixture of both.

* Please prepare one jupyter notebook per question.
* You can use any predefined function from numpy, scipy, math, pandas, random, collections and matplotlib modules -- for any other external module/library you should first ask for permission.
* Before submitting, download your notebooks as html as well as ipynb format and zip them all.
* Name your zip file as <YourName\>\_FIZ371_Final.zip (e.g., EmreTasci_FIZ371_Final.zip)


**Pick any 2 questions, if you have time go for a 3rd one for half the points (25) as bonus. Good luck! 8)**

<!-- #region -->
## 1. Probabilities
Consider the following text:

>Now you can use this probability distribution to generate new images. All you need to do is randomly generate new data points while adhering to the restriction that you generate more probable data more often — a process called “sampling” the distribution. Each new point is a new image.
>
>The same analysis holds for more realistic grayscale photographs with, say, a million pixels each. Only now, plotting each image requires not two axes, but a million. The probability distribution over such images will be some complex million-plus-one-dimensional surface. If you sample that distribution, you’ll produce a million pixel values. Print those pixels on a sheet of paper, and the image will likely look like a photo from the original data set.
>
>The challenge of generative modeling is to learn this complicated probability distribution for some set of images that constitute training data. The distribution is useful partly because it captures extensive information about the data, and partly because researchers can combine probability distributions over different types of data (such as text and images) to compose surreal outputs, such as a goldfish slurping Coca-Cola on a beach. “You can mix and match different concepts … to create entirely new scenarios that were never seen in training data,” said Anandkumar.


[Source: "The Physics Principle That Inspired Modern AI Art / Anil Ananthaswamy | Quanta Magazine](https://www.quantamagazine.org/the-physics-principle-that-inspired-modern-ai-art-20230105/)

* Discarding any non-letter character (including space) and ignoring case as well (i.e., treat "T" and "t" as same), calculate the following probabilities:

a) P(x="a")  
b) P(x="n")  
c) P(x="a"|y="n")  
d) P(x="n"|y="a")  
e) P(x="a",y="n")  

* (Bonus) Calculate the entropy.

* (Bonus) What is the meaning of the "plus-one" in the text: _The probability distribution over such images will be some complex **million-plus-one-dimensional surface**._ ?
<!-- #endregion -->

## 2. Parity Concept

Develop Hamming Code (8,4), calculate its probability error, discuss why HC(7,4) is preferable to HC(8,4) – compare it with the double repetition algorithm R2.


## 3. Central Limit Theorem
* Using the uniform distribution, pick 1000 values from [0,1) range. 
* Calculate its mean. 
* Repeat this procedure for 1000 times and collect the means of each try in an array called 'means'. 
* Plot the histogram of the means, try to fit a Gaussian to that histogram (or to the probabilities of the entries in the histogram).


## 4. Game of Life
On a hexagonal grid, implement the game of life with the rule set: B4/S34 (Born @ 4 / Survives @ 3 or 4).  
Use at least 6x6 tiles, apply periodic boundary conditions.

```python

```
