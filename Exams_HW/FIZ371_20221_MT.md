---
jupyter:
  jupytext:
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.11.5
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

**FIZ371 - Scientific & Technical Calculations | 07/12/2022**

Emre S. Tasci <emre.tasci@hacettepe.edu.tr>
Eng. Physics Dept.  
Hacettepe University  
Ankara, Turkey

# Midterm Exam
You can solve the problems analytically or stochastically, it's up to you. You can present your solution having been calculated on a paper, or as a jupyter notebook, or as a mixture of both.

* Please prepare one jupyter notebook per question.
* You can use any predefined function from numpy, scipy, math, pandas, random, collections and matplotlib modules -- for any other external module/library you should first ask for permission.
* Before submitting, download your notebooks as html as well as ipynb format and zip them all.
* Name your zip file as <YourName\>\_FIZ137_MT.zip (e.g., EmreTasci_FIZ137_MT.zip)


## 1. Probabilities
Please choose one from the following two questions:


### 1A - Dice Rolling
Suppose I have a box with a 6-sided die, an 8-sided die, and a 12-sided die. I choose one of the dice at random, roll it four times, and get 1, 3, 5, and 7. What is the probability that I chose the 8-sided die?


### 1B - Coin Tossing
Upon tossing a coin 8 times, calculate the probability that the number of heads will be greater than the number of tails.


## 2. Distributions
Please choose one from the following two questions:


### 2A - Borel Distribution
The Borel distribution is a discrete probability distribution defined as:

$$P_{mu}(n) = \frac{e^{-\mu n}(\mu n)^{n-1}}{n!}$$

for its variable $n=1,2,3,\dots$, and its parameter $\mu\in[0,1]$

Show that:  
a) it's normalized  
b) its mean is equal to (/converges to): $\frac{1}{1-\mu}$  
c) its variance is equal to: $\frac{\mu}{(1-\mu)^3}$

_**Bonus:** Plot its graph for $\mu_1 = 0.2$ and $\mu_2 = 0.7$_





### 2B - Gaussian Distribution
Sample $N=1000$ data points ($\{x_i\}$ from a Gaussian distribution with $\mu = 72$ and $\sigma=15$. Then, add a random noise of 10% to each data point and fit it to a Gaussian (by deriving the most suitable $\mu'$ and $\sigma'$, calculate the error $S_r'$ defined as:

$$S_r' = \sum_{i}{\left(y_i - G(x_i;\mu',\sigma')\right)^2}$$

and compare it to the error calculated with respect to your original $(\mu,\sigma)$:

$$S_r = \sum_{i}{\left(y_i - G(x_i;\mu,\sigma)\right)^2}$$


## 3. Game Theory
Please choose one from the following two questions:


### 3A - Path to Success

Tomorrow, early in the morning, you are to take an important exam. But the love of your life has asked for a meeting that night, which will definitely and negatively effect your exam performance on the following day. While you are pondering on this situation, unknown to you, your significant other receives a phone call for a meeting early in the morning from a company she/he had applied. And then, all the means of communications between you two disappears all of a sudden.

Construct the pay-off table stating your reasons. 
Draw the reaction-correspondence graph, indicate Nash equilibrium points if there are any.
Calculate the probabilities that each of you will attend tonight's meeting or not (if any of the probabilities is 0 or 1 then re-construct the pay-off table, and redo the calculations!)


### 3B - Nash in Real Life

|&nbsp; |$B_1$|$B_2$|$B_3$|
|-----|-----|----|----|
|$A_1$|20,20|30,30|10,20|
|$A_2$|40,30|50,20|20,25|
|$A_3$|30,20|60,0|30,10|


a) Find the Nash equilibrium point(s), if any.  
b) Treat this as the preference table for a Gale-Shapley matching (e.g., $A_2$ prefers $B_2$ with a 50 score but $B_2$ prefers $A_2$ with a 20 score) and find a stable matching, show that it's stable.

_**Attention:** the higher the score, the higher the preference! It's a score, not a rank!_


## 4. "You vs. You"

Propose and solve a question from any topic you wish as long as it isn't one of the topics of the above questions (and given that we have covered it in our lectures 8).

```python

```
